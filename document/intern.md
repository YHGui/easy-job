# Intern

## 总体概述

- 该项目是基于EnOS的历史数据导出模块，整个EnOS平台的数据一方面通过Kafka做在线处理，通过Spark Streaming做实时计算，另一方面通过Flume将数据抽取到HDFS上面，保存起来，以便后续做离线处理和分析。工作重心主要是从HDFS获取数据之后做离线处理为下游业务提供支持以及将数据备份起来，同时节省开支。
- 整个项目在生产环境上运行是在公司的内部离线调度平台Leopard，可以支持用户上传调度任务包，支持定期通过脚本命令执行调度，拥有图形化工作配置功能、任务重跑功能、任务日志在线查看功能、工作流复制功能以及警告功能，同时也能支持变量调用，项目每天定时运行一次。项目由四部分组成，第一部分是同步主数据，这里的主数据就是包含当前区域包含哪些场站、设备及其对应的物理属性的测点；第二部分是通过内部CANNAN离线处理平台跑MapReduce，将HDFS上的秒级时间序列数据抽取成不同时间粒度的数据和统计数据，为下游业务提供支持，第三部分是通过Spark将保存到HDFS的数据拉取到S3上面，第四部分是提供一个公共服务，将不同时间粒度的数据进行合并，提供给用户进行下载，并在前端进行展示。

## 详细介绍

### part 1

- 同步主数据服务是一个类似于公共服务的非web应用，是由我通过Spring Boot框架编写的一个服务，通过调用EnOS平台提供的api服务来获取并整合得到主数据，同时调度平台的定时服务中，会根据之前获取到的主数据进行对比，然后将新增加的主数据依次添加到之前的主数据后面，主数据存放到HDFS指定位置，这份数据在后续会经常被用到。
- 主数据的数据格式也是定义好的。

### part 2

- 第二部分是将HDFS上的秒级时间序列数据抽取成不同时间粒度的数据和统计数据，包括一分钟，五分钟，十分钟的粒度数据，同时还有统计数据，比如平均值以及矢量平均值等。其中MapReduce是通过CANNAN平台上编写的，CANNAN平台是针对能源领域的离线处理平台，构建了自定义的Key Value数据结构，方便map reduce各个阶段的数据处理，可以在配置文件中进行元数据的读写配置，可以在xml配置，包括输入数据源、Map类和Reduce类，同时还有包括采样周期和测点等信息，然后通过JAXB这个通过Java对象和xml绑定，然后能通过配置完成不同时间粒度的采样，在采样的过程包括三个mapping、gap filling interpolation插值等三个过程。  因为所有的任务是运行在调度平台中，我们可以通过之前获取的主数据来生成一个xml文件，通过xml文件来运行map reduce job。

### part 3

- 第三部分是通过将数据抽取出来放到S3上，之前使用的是淘宝数据平台部的一个工具，支持在异构的数据库／文件系统之间高速交换的工具，美团点评有一个blackhole的工具，由同事进行了更改为wormhole，用于数据导入或者导出。但是似乎速度特别慢，然后我们组里考虑直接使用Spark来开发，其中遇到一个问题就是发现Spark在抽取的时候很快，但是Spark在I/O期间导致不必要的开销，然后时间特别长，所以最后直接将一个数据分成不同的块然后发送到S3上，最后花费的时间从接近一个小时优化到10分钟左右，当然这种离线定时任务其实无所谓时间，但是还是做了优化，在做的时候也是大致完成了功能后续再进行优化。

### part 4

- 最后一部分提供接收http发送过来的数据，将数据进行合并压缩，最后提供公共下载服务。
- 写了几个后端接口，首先接收Spark那边发送过来的数据，然后是将文件做按照月时间跨度进行合并，然后是根据前端请求提供下载了。



