# 高级知识点

## 并行计算

- 将数据拆分到每个节点
  - 如何拆分数据：按尺寸切分，根据用户的信息
- 每个节点并行的计算出结果
  - 得到什么样的结果
- 将结果汇总
  - 如何汇总
- 外部排序：如何排序10G个元素？
  - 100M排序，秒级
  - 内存不够，数据放在硬盘等外部资源
  - 切分 -> 排序 -> 归并
  - k路归并排序，借助小顶堆（logn）实现就是用优先队列
  - 归并节点数据仍然是10G，如果全部读取还是内存不足，实际只是需要k个数据，但是每次使用优先队列push和pop之后，需要读取接下来的数据，这样会导致不断的读取硬盘，效率十分低，因此需要加一个缓冲区，实际程序会很复杂
  - 为了解决程序的复杂性，使用Iterable<T>接口，可以不断获取下一个元素的能力，元素存储／获取方式被抽象，与归并节点无关。
  - 归并数据源来自Iterable<T>.next()，如果缓冲区空，读取下一批元素放入缓冲区，给出缓冲区第一个元素，可配置项包括缓冲区大小，如何读取下一批元素。
- 归并排序
  - 将数据分为左右两半，分别归并排序，再把两个有序数据归并

## 多线程

- 线程和进程的区别：
  - 进程：在一个数据集合上运行程序，是系统进行资源分配和调度的一个独立运行的基本单位。
  - 线程：cpu在进程内切换的单位，作为进程的一部分，它由线程ID、程序计数器、寄存器集合和堆栈组成。它与隶属于同一进程的其他线程共享其代码段、数据段和其他操作系统资源（如打开文件和信号）。
  - 调度：线程作为调度和分派的基本单位，而进程作为资源拥有的基本单位。
  - 拥有资源：进程可以拥有资源，线程只能共享它隶属进程的资源，该资源主要包括一个进程的代码段、数据段及所拥有的系统资源，如已打开的文件、IO设备等。
  - 并发性：进程之间可以并发执行，同样线程之间也可以并发执行。
  - 系统开销：进程的系统开销>线程的系统开销。
- happens-before：
  - 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前；两个操作之间存在happens-before关系，并不意味着JMM的具体实现必须要按照happens-before关系指定的顺序来执行。
  - 如果重排序之后的执行结果与按照原来那种happens-before关系执行的结果一致，那么JMM允许编译器和处理器进行这种重排序。as-if-serial语义保证单线程内的程序执行结果不会改变，而happens-before则保证多线程的执行程序的执行结果不会发生改变。
- 死锁分析
  - synchronized锁住的是对象
  - 在任何地方都可以切换线程，甚至在一句语句中间
  - 要尽力设想对自己不利的情况
- 死锁条件
  - 互斥等待（有锁的存在）
  - hold and wait（拿着一个锁去等待另外一个锁）
  - 循环等待（拿了a的锁等待b，另一个拿了b的锁等待a的锁）
  - 无法剥夺的等待
- 死锁防止
  - 破除互斥等待，一般无法破除
  - 破除hold and wait： 一次性获取所有资源，暴露两个锁的object，并且两个锁之间有delay，如果不能同时锁住必须释放资源，然后继续等待后续再尝试（需要休息一段时间），不愿意反复等待的话，可以加入全局锁保护起来，可以保证同时拿到资源，全局锁不一定好。
  - 破除循环等待：按顺序获取资源，根据一定的规律来进行拿到锁
  - 无法剥夺的等待：加入超时，一定时间没有获取到资源，操作失败
- 线程池
  - 创建线程开销大，建立调用堆栈，操作系统要维护，当然比创建进程开销小；
  - 因此借用线程池预先建立好线程，等待任务派发，新任务很快被已经创建好的线程去执行并操作
  - 实现：线程池通过一个BlockingQueue进行任务派发，通常队列为空，这时候线程就在等待，等着抢任务，如果任务多，那么线程不足，队列中就会出现任务在排队的情况。
  - 线程池的参数：corePoolSize：线程池中初始线程数量，可能处于等待状态。maximumPoolSize：线程池中最大允许线程数量，在任务多的时候，可以扩张线程池。keepAliveTime：超出corePoolSize的线程如果等待了keepAliveTime会被回收。
  - Executor Framework：ThreadPoolExecutor Executors.newFixedThreadPool(num)
  - Future，可以cancel，get等待结果 Future<?>，不关心返回类型
  - 线程池的配置原则：
    - 我们知道线程是CPU执行的基本单位，单个处理器同一时间内只能运行一个线程，因此线程池的大小的配置，也应该与CPU的核心数目相关（通过Runtime.getRuntime().availableProcessors()方法可以获取到当前系统处理器数目），过多的创建线程并不一定能带来系统总体性能的提升，反而会使处理器性能浪费在频繁的线程切换中
    - 如果任务是CPU密集型任务，那么线程池应该配置较小，例如线程池可以配置CPU核心数目相等的大小；如果是需要资源等待类型的任务（如I/O等访问，数据库操作等），则应该根据等待的平均时间，来配置N倍于CPU核心数目的大小。线程池数目配置的具体的大小，还需要在实际开发工作中，编写行能测试类，结合虚拟机行能监控工具(如VisualVM)，来进行配置调优。
- notify(): 随机唤醒一个等待该对象同步锁的线程，进入就绪队列等待CPU的调度；这里的唤醒是由JVM确定唤醒哪个线程，而且不是按优先级决定。
- notifyAll():唤醒所有的等待该对象的同步的锁的进程，进入就绪队列等待CPU调度；注意唤醒的是notify之前wait的线程，对于notify之后的wait线程是没有效果的。
- wait():调用时需要先获得该object的锁，调用后，会把当前的锁释放掉同时阻塞住，但可以通过该object的notify或者notifyall来重新获得锁。
- sleep():在指定时间内让正在执行的线程暂停执行，但不会释放锁。
- 区别：
  - sleep()属于thread类，而其他三个属于object基础类，也就是每隔对象都有wait，notify，notifyall
  - sleep()不会释放锁，wait会释放锁
  - sleep必须捕获异常，wait，notify，notifyall不需要捕获异常
  - sleep可以在任何地方使用，而wait，notify，notifyall只能在同步控制方法或者同步控制块里面使用
- 线程的合并指的是：将指定的线程加入到当前的线程之中，可以将两个交替执行的线程合并为顺序执行的线程，如果在线程B中调用了线程A的Join()方法，直到线程A执行完毕后，才会继续执行线程B。
- 线程间通信
  - 通过synchronized/notify/notifyAll来实现线程之间的通信。
  - 利用了Java5中提供的Lock/Condition来实现线程之间的相互通信。
  - 使用信号量，如：CyclicBarrier/Semaphore/Countdownbatch。
- volatile线程可见性
  - 线程操作对volatile变量进行写操作时，JMM会将该线程的本地内存中的副本变量刷新到主存中去；当线程对volatile变量进行读操作时，线程先将本地内存共享变量设置为无效，线程就会从主存中读取共享变量的值了。
  - 可见性与锁的区别：
    - 锁控制的是代码块的同步，控制的是指令的执行顺序，而可见性指的是处理器确保共享变量在不同线程之间的可见，可见性不能保证共享变量操作的原子性，两者解决的问题不同，面对的对象也不同。
- CountDownLatch
  - CountDownLatch的构造函数接受一个int值作为计数器的初始值N，当程序调用countDown()的时候，N便会减1（体现出了倒数的意义），当N值减为0的时候，阻塞在await()的线程便会唤醒，继续执行。
- CyclicBarrier
  - CyclicBarrier就字面意思是可循环的屏障，其体现了两个特点，可循环和屏障。调用CyclicBarrier的await()方法便是在运行线程中插入了屏障，当线程运行到这个屏障时，便会阻塞在await()方法中，直到等待所有线程运行到屏障后，才会返回。
  - CyclicBarrier可以通过reset()方法，将N值重置，循环使用，而CountDownLatch的计数器是不能重置的。此外，CyclicBarrier还提供了一个更高级的用法，允许我们设置一个所有线程到达屏障后，便立即执行的Runnable类型的barrierAction（注意：barrierAction不会等待await()方法的返回才执行，是立即执行！）
- Semaphore
  - Semaphore信号量并发工具类，其提供了aquire()和release()方法来进行并发控制。Semaphore一般用于资源限流，限量的工作场景。
  - 例如数据库连接控制。假设数据库的最大负载在10个连接，而现在有100个客户端想进行数据查询，显然我们不能让100个客户端同时连接上来，找出数据库服务的崩溃。那么我们可以创建10张令牌，想要连接数据库的客户端，都必须先尝试获取令牌（Semaphore.aquire()），当客户端获取到令牌后便可以进行数据库连接，并在完成数据查询后归还令牌（Semaphore.release()），这样就能保证同时连接数据库的客户端不超过10个，因为只有10张令牌，这里给出该场景的模拟代码。
- CAS
  - CAS有三个操作参数：内存地址，期望值，要修改的新值，当期望值和内存当中的值进行比较不相等的时候，表示内存中的值已经被别线程改动过，这时候失败返回，只有相等时，才会将内存中的值改为新的值，并返回成功。
  - ABA问题
    - ABA问题是指在CAS操作时，其他线程将变量值A改为了B，但是又被改回了A，等到本线程使用期望值A与当前变量进行比较时，发现变量A没有变，于是CAS就将A值进行了交换操作，但是实际上该值已经被其他线程改变过，这与乐观锁的设计思想不符合。
      - ABA问题的解决思路是，每次变量更新的时候把变量的版本号加1，那么A-B-A就会变成A1-B2-A3，只要变量被某一线程修改过，改变量对应的版本号就会发生递增变化，从而解决了ABA问题。
- ThreadLocal
  - ThreadLocal主要为线程内部提供局部变量，这种变量在线程的生命周期内起作用。它并不能解决多线程访问共享变量，只为每个线程创建一个单独的变量副本。
  - 实现原理：每个Thread维护一个ThreadLocalMap映射表，这个映射表的key是ThreadLocal实例本身，value是真正需要存储的Object。ThreadLocalMap是使用ThreadLocal的弱引用作为Key的，弱引用的对象在GC时会被回收。
  - 它通过为每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题。一般来说，ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且对并发性处理效果更好。
  - 实际场景：例如：在并发环境下，服务器为每个用户开一个线程创建一个ThreadLocal变量来存放用户信息；对于数据库的并发操作，我们可以用一个ThreadLocal变量来存放Connection；在spring中也经常出现，如Bean、事务管理、任务调度、AOP等。
  - 由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。
  - ThreadLocal好的使用习惯，是每次使用完ThreadLocal，都调用它的remove()方法，清除数据。
- 守护线程与用户线程
  - 用户线程：我们平常创建的普通线程。
  - 守护线程：用来服务于用户线程；不需要上层逻辑介入。
  - 我们分析结果，可以得出结论：当线程只剩下守护线程的时候,JVM就会退出；补充一点如果还有其他的任意一个用户线程还在，JVM就不会退出。
  - 在Daemon线程中产生的新线程也是Daemon的。
  - Java自带的多线程框架，比如ExecutorService，会将守护线程转换为用户线程，所以如果要使用后台线程就不能用Java的线程池。
  - 当主线程结束时，结束其余的子线程（守护线程）自动关闭，就免去了还要继续关闭子线程的麻烦。如：Java垃圾回收线程就是一个典型的守护线程；内存资源或者线程的管理，但是非守护线程也可以。它的存在，必定有它的意义，只需在乎我们怎么把它用到恰到好处。
- 锁
  - 从本质上来说，moniterenter与moniterexit是一组排他的对某一对象监视器进行尝试获取的过程（该对象正是示例中的lock），同一时刻只有一个线程成功获取对象监视器。在线程运行到同步块时，会通过moniterenter指令尝试获取对象的监视器，如果获取成功，则进入同步块，执行同步块内指令，如果获取失败，则会进入同步队列（SynchronizedQueue）中进行等待，线程当前状态变为BLOCK（阻塞）状态，直到有线程释放监视器。
  - 线程对moniter的获取操作同步控制的核心依然是依靠CAS操作的原子性来实现的
- ReentrantLock
  - 重入这里指的是在某线程已经获取锁之后，该线程可以再次获取锁，进入同步代码块。这里需要强调一下重入的概念中所指的线程是已经获得锁的的线程，这与线程安全不冲突，因为只有一个线程可以获取锁，也就是说始终都是同一个线程（获取锁的线程）在运行同步代码，相当于单线程运行，当然是线程安全的。synchronized关键字也是支持重入的，例如synchronized可以在递归调用中使用。
  - synchronized与ReentrantLock的不同之处
    - ReentrantLock提供了显式加解锁操作。提供了lock(),unlock()方法进行加解锁的操作，而synchronized是隐式进行加锁与解锁操作（依赖于编译器将其编译为moniterenter与moniterexit）
    - 对锁的等待可以中断，在持有锁的线程长时间不释放锁时，等待锁的线程可以选择放弃等待，这样就避免了synchronized可能带来的死锁问题。ReentrantLock.tryLock()可以设置等待时间。
    - 对锁的等待可以中断，在持有锁的线程长时间不释放锁时，等待锁的线程可以选择放弃等待，这样就避免了synchronized可能带来的死锁问题。ReentrantLock.tryLock()可以设置等待时间。
- ReentrantReadWriteLock
  - 在大部分系统中，变量的读操作远远多于变量的写操作，大多情况下变量的值都是不变的，如果我们可以去除锁，并保证变量的改变能对所有线程可以及时可见，那么也不会存在脏读现象，这样就可以大幅度的提升系统的并发性能。读写锁正是基于上述需求产生的
  - 特性：
    - 在没有写操作线程获取写锁的情况下，所有读操作都可以获取读锁。
    - 在有写线程获取写锁的情况下，读操作等待写线程释放锁后，才可以获取读锁。
    - 在有读线程获取读锁的情况下，写线程会等待所有读线程释放锁后，才可以获取写锁，并且与此同时，所有的读锁也不可获取。
- CopyOnWriteArrayList
  - 在程序正常运行时所有读操作，都基于同一容器进行读操作，在容器进行写操作时，不是通过加锁来控制线程的写锁获取，而是先将容器完全复制出来一份，在新的容器上进行写操作，最后将旧容器的引用指向新容器，这样就完成了新容器的写操作。CopyOnWrite容器与读写锁（ReentrantReadWriteLock）的相同性质，进行了读写区别对待，只在写时加锁，从而提高了容器的性能。
  - 特性：
    - 读操作没有加锁,读操作不会存在线程阻塞等待现象。
    - 写操作会复制整个容器，有可能造成内存大幅增长，使用不当会导致java虚拟机频繁FullGC()。
    - 读操作不能立即可见。由于写操作是在新数组上进行的，因此新元素不可能对在旧数组上进行读操作的线程可见。
    - 适合在读操作频繁，容器元素稳定的生产环境中使用，并且一定要注意容器大小的控制，频繁的写操作会造成大内存的频繁申请与释放，有可能因此触发java虚拟机的stop-the-world。

## 资源管理

- Java垃圾回收
  - 不被引用的对象会被回收
  - 垃圾回收包括Minor GC和Full GC
  - 垃圾回收时所有的运行暂停
  - 对象创建太多太快也会触发GC，进入恶性循环
- Java资源管理
  - 内存会被回收，资源不会被释放
  - databaseConnection需要databaseConnection.close()来释放
- try catch finally 1.7 try with resourece

